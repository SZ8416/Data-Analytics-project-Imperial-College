{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clarification\n",
    "\n",
    "1) Before running any model, we do some pre-processing on the data set. There exists severe imbalance problem(the number of default and non-default data are very different), so we use SMOTE method to solve it. What's more, we convert all categorical variables into dummy ones and apply normalization on each variable. After pre-processing, we get 20000 sample(half default and half non-default) and 57 attributes for training.\n",
    "\n",
    "2) For question 6, we are supposed to select at most 10 variables using ridge method. We add ridge penalty to cost function, and select the coefficients with highest absolute values. However, the selected attribute set might include dummy variables; for example, the set can include both 'grade.B' and 'grade.C'. We will regard these sub-variables as the same one. We will enlarge the number of selected set until we acquire ten full variables(such as 'grade' and 'purpose')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Question 1: Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv('loans.csv')\n",
    "status_list = []\n",
    "for i in list(loans.loan_status):\n",
    "    if i == 'Fail':\n",
    "        status_list.append(1)\n",
    "    else:\n",
    "        status_list.append(0)\n",
    "loans.loan_status = status_list\n",
    "loans_dummy = pd.get_dummies(loans, drop_first=True, prefix_sep=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loans_dummy.drop(['loan_status'],axis=1),loans.loan_status\n",
    "clf = StandardScaler()\n",
    "X = clf.fit_transform(X)\n",
    "X,y=SMOTE().fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model: QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of QDA model is 0.71405\n"
     ]
    }
   ],
   "source": [
    "model_qda = QuadraticDiscriminantAnalysis()\n",
    "qda_accuracy= cross_val_score(model_qda, X, y, cv=10).mean()\n",
    "print(\"The accuracy of QDA model is \" + str(qda_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model: Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Tree model is 0.9025500000000001\n"
     ]
    }
   ],
   "source": [
    "model_tree = DecisionTreeClassifier()\n",
    "tree_accuracy = np.mean(cross_val_score(model_tree, X, y, cv=10))\n",
    "print(\"The accuracy of Tree model is \" + str(tree_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model: k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of 5-NN model is 0.7845500000000001\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_accuracy = np.mean(cross_val_score(model_knn, X, y, cv=10))\n",
    "print(\"The accuracy of 5-NN model is \" + str(knn_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Reduced Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_reduced_balanced = loans.loc[:, ['annual_inc', 'delinq_2yrs', 'tot_cur_bal', 'total_rec_prncp', 'verification_status', 'grade', \n",
    "                               'max_bal_bc', 'installment', 'total_rec_int', 'term', 'loan_status']]\n",
    "balanced_reduced_dummy = pd.get_dummies(loans_reduced_balanced, drop_first=True, prefix_sep=\".\")\n",
    "X_reduced, y = balanced_reduced_dummy.drop(['loan_status'],axis=1),balanced_reduced_dummy.loan_status\n",
    "clf = StandardScaler()\n",
    "X_reduced = clf.fit_transform(X_reduced)\n",
    "X_reduced,y=SMOTE().fit_sample(X_reduced, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Model: Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced, y = shuffle(X_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Tree reduced model is 0.651\n"
     ]
    }
   ],
   "source": [
    "model_log_reduced = LogisticRegression()\n",
    "log_reduced_accuracy = np.mean(cross_val_score(model_log_reduced, X_reduced, y, cv=10))\n",
    "print(\"The accuracy of Tree reduced model is \" + str(log_reduced_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Model: Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced, y = shuffle(X_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Tree reduced model is 0.79925\n"
     ]
    }
   ],
   "source": [
    "model_tree_reduced = DecisionTreeClassifier()\n",
    "tree_reduced_accuracy = np.mean(cross_val_score(model_tree_reduced, X_reduced, y, cv=10))\n",
    "print(\"The accuracy of Tree reduced model is \" + str(tree_reduced_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduced Model: K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced, y = shuffle(X_reduced, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of 5-NN reduced model is 0.8217000000000001\n"
     ]
    }
   ],
   "source": [
    "model_knn_reduced = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_reduced_accuracy = np.mean(cross_val_score(model_knn_reduced, X_reduced, y, cv=10))\n",
    "print(\"The accuracy of 5-NN reduced model is \" + str(knn_reduced_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5: Ridge-reduced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ridge, y = loans_dummy.drop(['loan_status'],axis=1),loans.loan_status\n",
    "clf = StandardScaler()\n",
    "X_ridge = clf.fit_transform(X_ridge)\n",
    "X_ridge,y=SMOTE().fit_sample(X_ridge, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C':10**np.arange(-4, 1, 0.1), 'penalty':['l2']}\n",
    "log = LogisticRegression()\n",
    "reg_cv = GridSearchCV(log, params, cv=5)\n",
    "reg_cv.fit(X_ridge, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of ridge reduced model is 0.7465499999999999\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "split = StratifiedKFold(y, n_folds=folds, shuffle = True, random_state = 0)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(split):\n",
    "    X_train, X_test, y_train, y_test = X_ridge[train], X_ridge[test], y[train], y[test]\n",
    "    ridge_clf = LogisticRegression(penalty='l2', C=4)\n",
    "    ridge_clf.fit(X_train, y_train)\n",
    "    betas = pd.DataFrame((abs(i) for i in ridge_clf.coef_.transpose()),columns=['beta'])\n",
    "    ridge_best_10 = betas.nlargest(10,'beta').index\n",
    "    logistic_clf = LogisticRegression()\n",
    "    logistic_clf.fit(X_train[:, ridge_best_10],y_train)\n",
    "    scores.append(logistic_clf.score(X_test[:, ridge_best_10], y_test))\n",
    "print(\"The accuracy of ridge reduced model is \" + str(sum(scores)/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ridge, y = loans_dummy.drop(['loan_status'],axis=1),loans.loan_status\n",
    "clf = StandardScaler()\n",
    "X_ridge = clf.fit_transform(X_ridge)\n",
    "X_ridge,y=SMOTE().fit_sample(X_ridge, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ridge_reduced2 = LogisticRegression(C=4, penalty='l2')\n",
    "log_ridge_reduced2.fit(X_ridge, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_coef = np.array([abs(i) for i in log_ridge_reduced2.coef_[0]])\n",
    "sig_variables = variable_coef.argsort()[-18:][::-1].tolist()\n",
    "for i in range(len(variable_coef)):\n",
    "    if i in sig_variables:\n",
    "        continue\n",
    "    else:\n",
    "        variable_coef[i] = 0\n",
    "index_list = []\n",
    "for i in range(len(variable_coef)):\n",
    "    if variable_coef[i] != 0:\n",
    "        index_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of ridge reduced model is 0.75595\n"
     ]
    }
   ],
   "source": [
    "X_ridge_10 = X_ridge[:, index_list]\n",
    "X_ridge_10, y1 = shuffle(X_ridge_10 ,y)\n",
    "model_reduced_ridge = LogisticRegression()\n",
    "reduced_ridge_accuracy = np.mean(cross_val_score(model_reduced_ridge, X_ridge_10, y1, cv=10))\n",
    "print(\"The accuracy of ridge reduced model is \" + str(reduced_ridge_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = loans_dummy.drop(['loan_status'],axis=1),loans.loan_status\n",
    "clf = StandardScaler()\n",
    "X = clf.fit_transform(X)\n",
    "X,y=SMOTE().fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Be careful, very slow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "params = {'max_features':range(50, 55), 'max_depth':range(18, 22)}\n",
    "rf_1 = RandomForestClassifier()\n",
    "rf_cv = GridSearchCV(rf_1, params, cv=5)\n",
    "rf_cv.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Tree model is 0.9122999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(max_features=rf_cv.best_param_['max_features'], max_depth=rf_cv.best_param_['max_depth'])\n",
    "tree_accuracy = np.mean(cross_val_score(rf, X, y, cv=10))\n",
    "print(\"The accuracy of Tree model is \" + str(tree_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
